\documentclass{article} % For LaTeX2e
\usepackage{nips14submit_e,times}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

\usepackage{bbm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{MnSymbol}

\def\eQb#1\eQe{\begin{eqnarray*}#1\end{eqnarray*}}
\def\eQnb#1\eQne{\begin{eqnarray}#1\end{eqnarray}}
\providecommand{\e}[1]{\ensuremath{\times 10^{#1}}}
\providecommand{\pb}[0]{\pagebreak}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand\eqD{\stackrel{\mathclap{\normalfont\mbox{d}}}{=}}

\def\Qb#1\Qe{\begin{question}#1\end{question}}
\def\Sb#1\Se{\begin{solution}#1\end{solution}}

\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newtheoremstyle{quest}{\topsep}{\topsep}{}{}{\bfseries}{}{ }{\thmname{#1}\thmnote{ #3}.}
\theoremstyle{quest}
\newtheorem*{definition}{Definition}
\newtheorem*{theorem}{Theorem}
\newtheorem*{lemma}{Lemma}
\newtheorem*{question}{Question}
\newtheorem*{preposition}{Preposition}
\newtheorem*{exercise}{Exercise}
\newtheorem*{challengeproblem}{Challenge Problem}
\newtheorem*{solution}{Solution}
\newtheorem*{remark}{Remark}
\usepackage{verbatimbox}
\usepackage{listings}
\usepackage{mathrsfs}
\title{ProbLimI: \\
Problem Set VI}


\author{
Youngduck Choi \\
CIMS \\
New York University\\
\texttt{yc1104@nyu.edu} \\
}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
This work contains solutions to the exercises of the problem set V. The
chosen problems are 1,2, and 3.
\end{abstract}

\bigskip

\begin{question}[1]
\hfill
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{prob-e6-p1.png}
\end{figure}
\end{question}
\begin{solution} \hfill \\
Observe that 
\eQb
\sum_{k=1}^{n} \mathbb{P}(A_k) &=& \mathbb{E}[S_n]  
\eQe 
for any $n \in \mathbb{N}$. As the LHS tends to $\infty$ as $n \to \infty$, 
we can choose $N$ large enough such that
$\mathbb{E}[S_n] > 0$ for all $n \geq N$. We relabel the indices to start from
$N$ so that the random variables $\{ \dfrac{S_n}{\mathbb{E}[S_n]}\}$ are well-defined
for the problem. 

\bigskip

\textbf{(i)} By independence,
\eQb
\Var(S_n) &=& \sum_{k=1}^{n} \Var(1_{A_k}) = \sum_{k=1}^{n} \mathbb{E}[1_{A_k}^2]
- \mathbb{E}[1_{A_k}]^2 = \sum_{k=1}^{n} \mathbb{P}(1_{A_k}) - 
\mathbb{P}(1_{A_k})^2 \\
&\leq& \sum_{k=1}^{n} \mathbb{P}(1_{A_k}) = \mathbb{E}[S_n]  
\eQe
for each $n \geq 1$. Now, we prove the claimed convergence in probability.
Let $\epsilon > 0$. By Chebyshev's inequality and the above result,
\eQb
\mathbb{P}(|\dfrac{S_n}{\mathbb{E}[S_n]} -1 | > \epsilon) &=&
\mathbb{P}(|S_n - \mathbb{E}[S_n]| > \epsilon \mathbb{E}[S_n]) \\
&\leq& \dfrac{\Var(S_n)}{\epsilon^2  \mathbb{E}[S_n]^2} \leq \dfrac{1}{\epsilon^2
\mathbb{E}[S_n]} 
\eQe
for any $ n \in \mathbb{N}$. Therefore, taking $n \to \infty$, 
\eQb
\lim_{n \to \infty} \mathbb{P}(|\dfrac{S_n}{\E[S_n]} - 1| > \epsilon) &=& 0.
\eQe
Since $\epsilon > 0$ was arbitrary, $\dfrac{S_n}{\E[S_n]} \to 1$ in probability. 

\bigskip

\textbf{(ii)} As $\mathbb{E}[S_n]$ tends to $\infty$ as $n \to \infty$, 
we can find a subsequence with the given property. 
Let $\epsilon > 0$. By the same argument as above, and the property
of the chosen subsequence, 
\eQb
\mathbb{P}(|\dfrac{S_n}{\mathbb{E}[S_n]} - 1| > \epsilon) &\leq& 
\dfrac{1}{\epsilon^2 \mathbb{E}[S_n]} \leq \dfrac{1}{\epsilon^2 k^2}  
\eQe
for all $k \in \mathbb{N}$, which implies
\eQb
\sum_{k=1}^{\infty} \mathbb{P}(|\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1| > 
\epsilon) < \infty.
\eQe
By Borel-Cantelli I, 
\eQb
\mathbb{P}(|\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1| > \epsilon \>\>\>\> \text{i.o.}) 
&=& 0
\eQe
for any $\epsilon > 0$. Now, by definition of pointwise convergence,
\eQb
\mathbb{P}(\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} \to 1) &=& 
\mathbb{P}(\bigcap_{\epsilon > 0} \{|\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1|
\leq \epsilon \>\> \text{a.a.} \} ) 
= 1 - \mathbb{P}(\bigcup_{\epsilon > 0} \{ |\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1|
> \epsilon \>\> \text{i.o.} \} )   
\eQe
By density of rationals and the above result,
\eQb
\mathbb{P}(\bigcup_{\epsilon > 0} \{ |\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1|
> \epsilon \>\> \text{i.o.} \} )  
&=& \mathbb{P}(\bigcup_{\epsilon > 0; \epsilon \in \mathbb{Q}}
\{ |\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1| > \epsilon \>\> \text{i.o.}\}) \\ 
&\leq&
\sum_{\epsilon > 0; \epsilon \in \mathbb{Q}}
\mathbb{P}(
|\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} - 1| > \epsilon \>\> \text{i.o.}) = 0 
\eQe
and hence
\eQb
\dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} &\to& 1 \>\>\> \text{almost surely}.
\eQe

\bigskip

\textbf{(iii)} Observe that 
\eQb
|\mathbb{E}[S_{n+1}] - \mathbb{E}[S_{n}]| = \mathbb{P}(A_{n+1}) \leq 1 
\eQe
for all $n \geq 1$, which implies that 
$\{n_k\}$ chosen is strictly increasing as a function $k$ and 
\eQb
\mathbb{E}[S_{n_{k}}] &<& (k+1)^2  
\eQe 
for all $k \geq 1$. Therefore,
\eQb
1 &\leq& \dfrac{\mathbb{E}[S_{n_{k+1}}]}{\mathbb{E}[S_{n_{k}}]} 
\leq \dfrac{(k+2)^2}{k^2} 
\eQe
for all $k \geq 1$, and hence, taking $k \to \infty$, 
\eQb
\lim_{k \to \infty} \dfrac{\mathbb{E}[S_{n_{k+1}}]}{\mathbb{E}[S_{n_{k}}]} &=& 1. 
\eQe
Now, let $w \in \Omega$ such that $\dfrac{S_{n_k(w)}}{\mathbb{E}[S_{n_k}]} \to 1$.
Recall that
\eQb
S_{n}(w) \leq S_{n+1}(w) \>\>\>\> &\text{and}& \>\>\>\> 
\mathbb{E}[S_n] \leq \mathbb{E}[S_{n+1}]  
\eQe
for all $n \geq 1$, and hence
\eQb
\dfrac{\mathbb{E}[S_{n_{k}}]}{\mathbb{E}[S_{n_{k+1}}]} 
\dfrac{S_{n_k}(w)}{\mathbb{E}[S_{n_{k}}]} 
= \dfrac{S_{n_k}(w)}{\mathbb{E}[S_{n_{k+1}}]} &\leq&
\dfrac{S_{n}(w)}{\mathbb{E}[S_{n}]} \leq 
\dfrac{S_{n_{k+1}}(w)}{\mathbb{E}[S_{n_{k}}]}  
=
\dfrac{S_{n_{k+1}}(w)}{\mathbb{E}[S_{n_{k+1}}]} 
\dfrac{\mathbb{E}[S_{n_{k+1}}]}{\mathbb{E}[S_{n_{k}}]} 
\eQe
for any $k \in \mathbb{N}$ and $n_{k} \leq  n < n_{k+1}$. Set
\eQb
L_n = \dfrac{\mathbb{E}[S_{l}]}{\mathbb{E}[S_{u}]} 
\dfrac{S_{l}(w)}{\mathbb{E}[S_{l}]} \>\>\> &\text{and}& \>\>\>
U_n = \dfrac{\mathbb{E}[S_{u}]}{\mathbb{E}[S_{l}]} 
\dfrac{S_{u}(w)}{\mathbb{E}[S_{u}]} 
\eQe
where $l = \sup \{ n_k  \> : \> n_k \leq n ; k \in \mathbb{N} \}$
and $u = \inf 
\{ n_k  \> : \> n_k > n ; k \in \mathbb{N} \}$, for any $n \in \mathbb{N}$.
Then,
\eQb
1 = \lim_{n \to \infty} L_n
\leq
\limsup_{n \to \infty} \dfrac{S_{n}(w)}{\mathbb{E}[S_{n}]} \leq 
\liminf_{n \to \infty}  \dfrac{S_{n}(w)}{\mathbb{E}[S_{n}]} \leq 
\lim_{n \to \infty} U_n = 1
\eQe
and hence
\eQb
\{ \dfrac{S_{n_k}}{\mathbb{E}[S_{n_k}]} \to 1 \}
&\subset&
\{ \dfrac{S_{n}}{\mathbb{E}[S_{n}]} \to 1 \}
\eQe
which implies
\eQb
\dfrac{S_{n}}{\mathbb{E}[S_{n}]} &\to& 1 \>\>\> \text{almost surely}.
\eQe
\hfill $\qed$
\end{solution}

\newpage

\begin{question}[2]
\hfill
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{prob-e6-p2.png}
\end{figure}
\end{question}
\begin{solution} \hfill \\
\textbf{(a)} As $X$ is non-negative real-valued RV and
$1_{\{ X \geq n \} }(w) = 0$ for each $n > \max\{k \in \mathbb{N} 
\> : \> k \leq X(w) \}$. 
\eQb 
\lfloor X(w) \rfloor &=& 
\max\{k \in \mathbb{N} \> : \> k \leq X(w) \} = \sum_{n=1}^{\max\{
k \in \mathbb{N} \> : \> k \leq X(w) \}} 1_{\{X \geq n\}}(w) 
= \sum_{n=1}^{\infty} 1_{\{X \geq n\}}(w) 
\eQe
for any $w \in \Omega$, and hence
\eQb
\lfloor X \rfloor &=& \sum_{n=1}^{\infty}1_{\{ X \geq n\}} = Y.
\eQe 
Observe that $\{\sum_{n=1}^k 1_{\{X \geq n\}}\}_{k}$ is a pointwise
non-decreasing and non-negative sequence of RVs, which converges pointwise
everywhere to $Y = \lfloor X \rfloor$.
Hence, by MCT,
\eQb
\mathbb{E} Y &=& \sum_{n=1}^{\infty} \mathbb{E} 1_{\{X \geq n\}} 
= \sum_{n=1}^{\infty} \mathbb{P}(X \geq n).
\eQe 

Since $X - 1 \leq \lfloor X \rfloor \leq X$, if $X$ is integrable, 
by monotonicity of integration,
\eQb
\mathbb{E}[X] - 1 &\leq& \sum_{n=1}^{\infty} \mathbb{P}(X \geq n) \leq 
\mathbb{E}[X].
\eQe
If $\mathbb{E}[X] = \mathbb{E}[X] - 1 = \infty$, 
then $X-1$ is not integrable, as otherwise it will contradict the non-integrability of
$X$ by linearity. Therefore, $\mathbb{E}[Y] = \mathbb{E}[X-1] = \infty$, so
the inequality holds trivially. 

\bigskip

\textbf{(b)} Let $\beta > 0$. Observe that
\eQb
\sum_{n=0}^{\infty} 1_{\{\beta^{-\alpha} |X_1|^{\alpha} > n\}} &=& 
\lceil \beta^{-\alpha}|X_1|^{\alpha} \rceil.
\eQe 
Similar to (a), by MCT,
\eQb
\sum_{n=0}^{\infty} \mathbb{P}(\beta^{-\alpha} |X_1|^{\alpha} > n ) 
&=& \mathbb{E}\lceil \beta^{-\alpha}|X_1|^{\alpha} \rceil . 
\eQe
We now have the following pointwise estimate:
\eQb
\beta^{-\alpha} |X_1|^{\alpha} &\leq& \lceil \beta^{-\alpha} |X_1|^{\alpha} \rceil. 
\eQe
As $\mathbb{E}|X_1|^{\alpha} = \infty$, we see $\mathbb{E}[\beta^{-\alpha}|X_1|^{\alpha}]
= \infty$ and combined with the above estimate 
\eQb
\sum_{n=0}^{\infty} \mathbb{P}(|X_n| > \beta n^{\frac{1}{\alpha}}) = 
\sum_{n=0}^{\infty} \mathbb{P}(\beta^{-\alpha} |X_1|^{\alpha} > n ) &=&
\infty
\eQe
which implies
\eQb
\sum_{n=1}^{\infty} \mathbb{P}(|X_n| > \beta n^{\frac{1}{\alpha}}) &=& \infty. 
\eQe
Since $\beta > 0$ was arbitrary, we have the result for all $\beta > 0$.

\smallskip

Set
\eQb
A_k &=& \{ n^{-\frac{1}{\alpha}} |X_n| > k \>\>\> \text{ i.o.} \} 
\eQe
for each $k \in \mathbb{N}$. By Borel-Cantelli II, combined with the above result,
\eQb
\mathbb{P}(A_k) = 1
\eQe
for each $k \in \mathbb{N}$. Since $\{ A_k \}$ is descending, by continuity of 
probability,
\eQb
\mathbb{P}(\bigcap_{k=1}^{\infty} A_k) &=& 1.
\eQe
Suppose $w \in \bigcap_{k=1}^{\infty} A_k$. By induction, we construct
a subsequence, which diverges to $\infty$. Choose $n_1$ such that 
\eQb
(n_{1})^{-\frac{1}{\alpha}}|X_{n_1}(w)| > 1.
\eQe
Given $\{n_i\}_{i=1}^{l}$, choose $n_{l+1}$ larger than all previous indices such that 
\eQb
(n_{l+1})^{-\frac{1}{\alpha}}|X_{n_{l+1}}(w)| > l + 1.
\eQe
By induction, we have constructed a subsequence $\{n_l\}$ such that
\eQb
(n_{l})^{-\frac{1}{\alpha}}|X_{n_{l}}(w)| > l
\eQe
for each $l \in \mathbb{N}$, and hence
\eQb
\bigcap_{k=1}^{\infty} A_k &\subset& 
\{ \limsup_{n \to \infty} n^{-\frac{1}{\alpha}} |X_n|  = \infty \}.
\eQe
Therefore, 
\eQb
\limsup_{n \to \infty} n^{-\frac{1}{\alpha}} |X_n| = \infty \>\>\> \text{a.s.}
\eQe

\bigskip

\textbf{(c)}
Firstly, by reverse triangle inequality,
\eQb
|n^{-\frac{1}{\alpha}}|S_{n-1}| - n^{-\frac{1}{\alpha}}|X_n|| 
 &\leq& n^{-\frac{1}{\alpha}} |S_n| 
\eQe
for all $n \geq 2$, and hence, by elementary properties of $\limsup$
\eQb
\limsup n^{-\frac{1}{\alpha}} |X_n| &\leq& 
\limsup (n^{-\frac{1}{\alpha}} |X_n| - n^{-\frac{1}{\alpha}} |S_{n-1}|) 
+ \limsup n^{-\frac{1}{\alpha}} |S_{n-1}| \\
&=& 
\limsup (n^{-\frac{1}{\alpha}} |X_n| - n^{-\frac{1}{\alpha}} |S_{n-1}|) 
+ \limsup (n-1)^{-\frac{1}{\alpha}} |S_{n-1}| 
\limsup (\dfrac{n}{n-1})^{-\frac{1}{\alpha}} \\
&=& 
\limsup (n^{-\frac{1}{\alpha}} |X_n| - n^{-\frac{1}{\alpha}} |S_{n-1}|) 
+ \limsup n^{-\frac{1}{\alpha}} |S_{n}| \\
&\leq& 
2\limsup n^{-\frac{1}{\alpha}} |S_{n}|.
\eQe 
By the above estimate,
\eQb
\{ \limsup n^{-\frac{1}{\alpha}} |X_n| = \infty\} &\subset& 
\{ \limsup n^{-\frac{1}{\alpha}} |S_n| = \infty\}
\eQe
and hence
\eQb
\limsup n^{-\frac{1}{\alpha}}|S_n| = \infty &\>\>\>& \text{a.s.}
\eQe

\end{solution}

\newpage

\begin{question}[3]
\hfill
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{prob-e6-p3.png}
\end{figure}
\end{question}
\begin{solution} \hfill \\
Verbatim repeat the argument given in the problem $2$ to have
\eQb
\mathbb{E}|X| < \infty &\iff& \sum_{n} \mathbb{P}(|X| > n) \>\> \text{converges}
\eQe
and
\eQb
\mathbb{E}X_{+} < \infty &\iff& \sum_{n} \mathbb{P}(X > n) \>\> \text{converges}.
\eQe

\smallskip

\textbf{(a)} As $(X_n)$ are identically distributed,
\eQb
\sum_{n} \mathbb{P}(|X_1| > n) &=& \sum_n \mathbb{P}(|X_n| > n). 
\eQe
Therefore, by Borel-Cantelli I,II and the above equivalences
\eQb
\mathbb{P}(|X_n| > n \>\> \text{i.o.} ) = 0  &\iff& \mathbb{E}|X_1| < \infty.
\eQe

\smallskip

\textbf{(b)} Suppose $\mathbb{E}|X_1| < \infty$. Then,
\eQb
\mathbb{E}|\dfrac{X_1}{\alpha}| < \infty
\eQe
so, by $(a)$
\eQb
\mathbb{P}(n^{-1}|X_n| > \alpha \>\> \text{i.o.}) = 0
\eQe
for any $\alpha > 0$. By the same argument given in $1-b$,
\eQb
n^{-1}|X_n| \to 0 \>\> \text{a.s.} 
\eQe
Conversely, suppose $n^{-1}X_n \to 1$ a.s. Observe that
\eQb
\{ n^{-1}X_n \to 0\} 
&=& \bigcap_{\alpha > 0} \{ n^{-1}X_n \leq \alpha \>\> \text{a.a.} \}.
\eQe
With $\alpha = 1$,
\eQb
\mathbb{P}(n^{-1}|X_n| \leq 1 \>\> \text{a.a.}) = 1
\eQe
so 
\eQb
\mathbb{P}(|X_1| > n \>\> \text{i.o.}) = 0.
\eQe
which by (a) implies $\mathbb{E}|X_1| < \infty$.

\smallskip

\textbf{(c)} We first show the forward direction. Assume $n^{-1}M_n \to 0$ a.s. 
Suppose for sake of contradiction that $\mathbb{P}(X_1 > -\infty) = 0$.
Then, $M_n = -\infty$ a.s. for all $n \geq 1$. Therefore, $n^{-1}M_n \to -\infty$
a.s, which is a contradiction, and $\mathbb{P}(X_1 > -\infty) > 0$. Now, 
suppose again for sake of contradiction that $\mathbb{E}(X_1)_{+} = \infty$, then by the 
equivalence established before, and Borel Cantelli II, we have
$\mathbb{P}(\{X_n > n \>\> \text{i.o.} \}) = 1$. Then, it follows that
for a.s. $w \in \Omega$, there exists a subsequence $X_{n_k}(w) > 1$ for all $k$,
and 
\eQb
\limsup M_n(w) \geq \limsup X_n(w) \geq 1 \>\>\> \text{a.s.} 
\eQe
which is a contradiction. Now, conversely, suppose there exists a set $A$ 
with positive probability, where $n^{-1}M_n \not\to 0$. There are two possible cases
$\mathbb{P}(X_1 > \infty) = 0$ or $\mathbb{P}(X_1 > \infty) > 0$. It suffices to 
show that if $\mathbb{P}(X_1 >$ 

\smallskip

By iid assumption,
\eQb
\mathbb{P}(n^{-1}M_n > \epsilon) &=& 1 - \mathbb{P}(n^{-1}M_n \leq \epsilon)
= 1 - \mathbb{P}(|n^{-1}X_1| \leq \epsilon)^n = 1 - (1 -\mathbb{P}(|n^{-1}X_1| >
\epsilon)^n 
\eQe
for any $\epsilon > 0$ and $n \geq 1$. Hence
\eQb
\lim_{n} \mathbb{P}(n^{-1}M_n > \epsilon) = 1 - \exp(-\mathbb{P}(|n^{-1}X_1| > 
\epsilon)) 
\eQe 
provided the limit exists.


\smallskip

\textbf{(d)} Since
\eQb
\{|X_1| < \infty \} &=& \{ \dfrac{|X_1|}{\epsilon} < \infty \} 
= \bigcup_{n=1}^{\infty} \{ \dfrac{|X_1|}{\epsilon} \leq n \} 
\eQe 
by continuity of probability,
\eQb
\mathbb{P}(|X_1| < \infty) = 1 - \lim_n \mathbb{P}(|n^{-1}X_n| > \epsilon)
\eQe
for any $\epsilon > 0$. Therefore,
\eQb
\mathbb{P}(|X_1| < \infty) = 1 &\iff& \lim_n \mathbb{P}(|n^{-1}X_n| > \epsilon) = 0 
\>\> \forall \epsilon > 0.
\eQe
By definition $n^{-1}X_n \to_{p} 0$ iff
\eQb
\lim_{n} \mathbb{P}(|n^{-1}X_n| > \epsilon) = 0
\eQe
for any $\epsilon > 0$, so we are done. \hfill $\qed$


\end{solution}

\newpage

\begin{question}[4]
\hfill
\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{prob-e6-p4.png}
\end{figure}
\end{question}
\begin{solution} \hfill \\
\textbf{(a)}
Let $b_0, s_0  = 0$ and
$s_n = \sum_{k=1}^{n} \dfrac{a_n}{b_n}$, so $a_n = b_n(s_n - s_{n-1})$ for each $n 
\in \mathbb{N}$.
Observe that
\eQb
\dfrac{1}{b_n}\sum_{k=1}^{n} a_n &=& \dfrac{1}{b_n} \sum_{k=1}^{n}
b_k(s_k - s_{k-1}) = s_n - \sum_{k=1}^{n} (\dfrac{b_k - b_{k-1}}{b_n}) s_{k-1}  
\eQe 
for each $n \in \mathbb{N}$. Let $s_{\infty}$ be the limit of $\{s_n\}$. It suffices
to show that the right most term on the above formula converges to $s_{\infty}$.
Let $\epsilon > 0$. By triangle inequality,
\eQb
|\sum_{k=1}^{n} (\dfrac{b_k - b_{k-1}}{b_n}) s_{k-1} - s_{\infty}| 
&\leq& \sum_{k=1}^{n} (\dfrac{b_k - b_{k-1}}{b_n}) |s_{k-1} - s_{\infty}| \\
&=& \sum_{k=1}^{m} (\dfrac{b_k - b_{k-1}}{b_n})|s_{k-1} - s_{\infty}| 
+ \sum_{k=m+1}^{n} (\dfrac{b_k - b_{k-1}}{b_n})|s_{k-1} - s_{\infty}|  
\eQe  
for each $1 \leq m < n$. Choose $m_0$ such that $|s_{n} - s_{\infty}| < \epsilon$ for
each $n \geq m_0$. Then 
\eQb
|\sum_{k=1}^{n} (\dfrac{b_k - b_{k-1}}{b_n}) s_{k-1} - s_{\infty}| 
&\leq& \dfrac{1}{b_n} \sum_{k=1}^{m_0} 
(b_k - b_{k-1})|s_{k-1} - s_{\infty}| 
+ \dfrac{b_n - b_{m_0}}{b_n} \epsilon  
\eQe 
for each $n \geq m_0$. Letting $n \to \infty$,
\eQb
|\sum_{k=1}^{n} (\dfrac{b_k - b_{k-1}}{b_n}) s_{k-1} - s_{\infty}| < \epsilon 
\eQe
as required.

\bigskip

\textbf{(b)} 

\bigskip

\textbf{(c)} 

\end{solution}
\end{document}
